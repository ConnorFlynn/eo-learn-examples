{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration transform example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates how to use a RegistrationTransform to temporally align the frames of an EOPatch using different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cloudless timelapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports from `sentinelhub` and `eolearn` to set up workflow that creates a timelapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from eolearn.core import FeatureType\n",
    "from eolearn.features import SimpleFilterTask\n",
    "from eolearn.io import SentinelHubInputTask\n",
    "from sentinelhub import CRS, BBox, DataCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up BBox of ROI and time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_bbox = BBox(bbox=[31.112895, 29.957240, 31.154222, 29.987687], crs=CRS.WGS84)\n",
    "# roi_bbox = BBox(bbox=[-6.57257, 37.2732, -5.728, 36.8549], crs=CRS.WGS84)\n",
    "time_interval = (\"2018-01-01\", \"2020-06-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This predicate function filters the images with a cloud coverage larger than a threshold to ensure images do not contain cloudy pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxCCPredicate:\n",
    "    def __init__(self, maxcc):\n",
    "        self.maxcc = maxcc\n",
    "\n",
    "    def __call__(self, img_cm):\n",
    "        w, h, _ = img_cm.shape\n",
    "        cc = np.sum(img_cm) / (w * h)\n",
    "        return cc <= self.maxcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks of the workflow:\n",
    " * download S2 images (only 3 bands needed for true color visualitzation)\n",
    " * Download cloud mask (CLM) provided by Sentinel Hub  \n",
    " * filter out images with cloud coverage larger than a given threshold (e.g. 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_task = SentinelHubInputTask(\n",
    "    data_collection=DataCollection.SENTINEL2_L1C,\n",
    "    bands_feature=(FeatureType.DATA, \"BANDS\"),\n",
    "    resolution=10,\n",
    "    maxcc=0.5,\n",
    "    bands=[\"B02\", \"B03\", \"B04\"],\n",
    "    time_difference=datetime.timedelta(hours=2),\n",
    "    additional_data=[(FeatureType.MASK, \"dataMask\", \"IS_DATA\"), (FeatureType.MASK, \"CLM\")],\n",
    ")\n",
    "filter_clouds = SimpleFilterTask((FeatureType.MASK, \"CLM\"), MaxCCPredicate(maxcc=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and execute timelapse as chain of transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch = download_task.execute(bbox=roi_bbox, time_interval=time_interval)\n",
    "eopatch_clean = filter_clouds.execute(eopatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get result as an eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data={\n",
       "    BANDS: numpy.ndarray(shape=(130, 331, 404, 3), dtype=float32)\n",
       "  }\n",
       "  mask={\n",
       "    CLM: numpy.ndarray(shape=(130, 331, 404, 1), dtype=uint8)\n",
       "    IS_DATA: numpy.ndarray(shape=(130, 331, 404, 1), dtype=bool)\n",
       "  }\n",
       "  meta_info={\n",
       "    maxcc: 0.5\n",
       "    size_x: 404\n",
       "    size_y: 331\n",
       "    time_difference: 7200.0\n",
       "    time_interval: ('2018-01-01T00:00:00', '2020-06-01T23:59:59')\n",
       "  }\n",
       "  bbox=BBox(((31.112895, 29.95724), (31.154222, 29.987687)), crs=CRS('4326'))\n",
       "  timestamp=[datetime.datetime(2018, 1, 4, 8, 33, 28), ..., datetime.datetime(2020, 5, 28, 8, 41, 58)], length=130\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eopatch_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Help function to create GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import imageio\n",
    "\n",
    "\n",
    "def make_gif(eopatch, project_dir, filename, fps):\n",
    "    \"\"\"\n",
    "    Generates a GIF animation from an EOPatch.\n",
    "    \"\"\"\n",
    "    with imageio.get_writer(os.path.join(project_dir, filename), mode=\"I\", fps=fps) as writer:\n",
    "        for image in eopatch:\n",
    "            writer.append_data(np.array(np.clip(2.8 * image[..., [2, 1, 0]], 0, 255), dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write clean EOPatch to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_clean.data[\"BANDS\"] * 255, project_dir=\".\", filename=\"eopatch_clean.gif\", fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run registrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import registrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eolearn.coregistration import ECCRegistrationTask, PointBasedRegistrationTask\n",
    "from eolearn.coregistration.extra.thunder import ThunderRegistrationTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor of the Registration objects takes the attribute type, field name and index of the channel to be used for registration, a dictionary specifying the parameters of the registration, and the interpolation method to be applied to the images. The interpolation methods are (NEAREST, LINEAR and CUBIC). Default is CUBIC. A nearest neighbour interpolation is used on ground-truth data to avoid creation of new labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thunder registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm computes translations only between pairs of images, using correlation on the Fourier transforms of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/registration/algorithms/crosscorr.py:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray([key, self._get(image, reference)])\n"
     ]
    }
   ],
   "source": [
    "coregister_thunder = ThunderRegistrationTask((FeatureType.DATA, \"BANDS\"), channel=2)\n",
    "\n",
    "eopatch_thunder = coregister_thunder(eopatch_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write result to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_thunder.data[\"BANDS\"] * 255, project_dir=\".\", filename=\"eopatch_thunder.gif\", fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Cross-Correlation in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm uses intensity values to maximise cross-correlation between pair of images. It uses an Euler transformation (x,y translation plus rotation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"MaxIters\": 200}\n",
    "coregister_ecc = ECCRegistrationTask((FeatureType.DATA, \"BANDS\"), channel=2, params=params)\n",
    "\n",
    "eopatch_ecc = coregister_ecc(eopatch_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_ecc.data[\"BANDS\"] * 255, project_dir=\".\", filename=\"eopatch_ecc.gif\", fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-Based Registration in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three transformation models are supported for point-based registration, i.e. Euler, PartialAffine and Homography. These methods compute feature descriptors (i.e. SIFT or SURF) of the pair of images to be registered, and estimate a robust transformation using RANSAC to align the matching points. These methods perform poorly compared to the other methods due to the inaccuracies of the feature extraction, point-matching and model fitting. If unplausible transformations are estimated, a warning is issued and an identity matrix is employed instead of the estimated transform. Default parameters are (Model=Euler, Descriptor=SIFT, RANSACThreshold=7.0, MaxIters=1000).\n",
    "\n",
    "Note: In case the following cell will raise an error\n",
    "\n",
    "```Python\n",
    "AttributeError: module 'cv2.cv2' has no attribute 'xfeatures2d'\n",
    "```\n",
    "\n",
    "uninstall and reinstall Python package `opencv-contrib-python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@963.528] global /io/opencv_contrib/modules/xfeatures2d/misc/python/shadow_sift.hpp (13) SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 118 and 117\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 117 and 116\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:235: RuntimeWarning: invalid value encountered in arccos\n",
      "  rot_angle = np.arccos(cos_theta)\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 104 and 103\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 76 and 75\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 75 and 74\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 69 and 68\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 68 and 67\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 67 and 66\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 66 and 65\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 21 and 20\n",
      "  warnings.warn(\n",
      "/home/jgersak/Documents/Projects/NotebookUpdate/coregistration/lib/python3.8/site-packages/eolearn/coregistration/coregistration.py:170: EORuntimeWarning: A problem in pair-wise registration of time slices 20 and 19\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = {\"Model\": \"Euler\", \"Descriptor\": \"SURF\", \"RANSACThreshold\": 7.0, \"MaxIters\": 1000}\n",
    "\n",
    "coregister_pbased = PointBasedRegistrationTask((FeatureType.DATA, \"BANDS\"), channel=2, params=params)\n",
    "\n",
    "eopatch_pbased = coregister_pbased(eopatch_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(eopatch=eopatch_pbased.data[\"BANDS\"] * 255, project_dir=\".\", filename=\"eopatch_pbased.gif\", fps=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
