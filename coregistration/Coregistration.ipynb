{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration transform example\n",
    "\n",
    "This example illustrates how to use a RegistrationTransform to temporally align the frames of an EOPatch using different algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cloudless timelapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "from eolearn.core import FeatureType\n",
    "from eolearn.core.exceptions import EORuntimeWarning\n",
    "from eolearn.coregistration import ECCRegistrationTask, PointBasedRegistrationTask\n",
    "from eolearn.coregistration.extra.thunder import ThunderRegistrationTask\n",
    "from eolearn.features import SimpleFilterTask\n",
    "from eolearn.io import SentinelHubInputTask\n",
    "from sentinelhub import CRS, BBox, DataCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code raises warnings when automatically adjusting problematic data, which we ignore in the notebook for clarity.\n",
    "warnings.filterwarnings(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=EORuntimeWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up BBox of ROI and time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_bbox = BBox(bbox=[31.112895, 29.957240, 31.154222, 29.987687], crs=CRS.WGS84)\n",
    "time_interval = (\"2018-01-01\", \"2020-06-01\")\n",
    "\n",
    "feat_bands = (FeatureType.DATA, \"BANDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This predicate function filters the images with a cloud coverage larger than a threshold to ensure images do not contain cloudy pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxCloudCoveragePredicate:\n",
    "    def __init__(self, max_cloud_coverage: float):\n",
    "        self.max_cloud_coverage = max_cloud_coverage\n",
    "\n",
    "    def __call__(self, cloud_mask: np.ndarray):\n",
    "        width, height, _ = cloud_mask.shape\n",
    "        cloud_coverage = np.sum(cloud_mask) / (width * height)\n",
    "        return cloud_coverage <= self.max_cloud_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    " * download S2 images (bands needed for true color visualization)\n",
    " * download cloud mask (CLM) provided by Sentinel Hub\n",
    " * filter out images with cloud coverage larger than a given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_task = SentinelHubInputTask(\n",
    "    data_collection=DataCollection.SENTINEL2_L1C,\n",
    "    bands_feature=feat_bands,\n",
    "    resolution=10,\n",
    "    maxcc=0.5,\n",
    "    bands=[\"B02\", \"B03\", \"B04\"],\n",
    "    time_difference=datetime.timedelta(hours=2),\n",
    "    additional_data=[(FeatureType.MASK, \"dataMask\", \"IS_DATA\"), (FeatureType.MASK, \"CLM\")],\n",
    ")\n",
    "filter_clouds = SimpleFilterTask((FeatureType.MASK, \"CLM\"), MaxCloudCoveragePredicate(max_cloud_coverage=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute timelapse as chain of transforms and get result as an eopatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EOPatch(\n",
       "  data={\n",
       "    BANDS: numpy.ndarray(shape=(130, 331, 404, 3), dtype=float32)\n",
       "  }\n",
       "  mask={\n",
       "    CLM: numpy.ndarray(shape=(130, 331, 404, 1), dtype=uint8)\n",
       "    IS_DATA: numpy.ndarray(shape=(130, 331, 404, 1), dtype=bool)\n",
       "  }\n",
       "  meta_info={\n",
       "    maxcc: 0.5\n",
       "    size_x: 404\n",
       "    size_y: 331\n",
       "    time_difference: 7200.0\n",
       "    time_interval: ('2018-01-01T00:00:00', '2020-06-01T23:59:59')\n",
       "  }\n",
       "  bbox=BBox(((31.112895, 29.95724), (31.154222, 29.987687)), crs=CRS('4326'))\n",
       "  timestamp=[datetime.datetime(2018, 1, 4, 8, 33, 28), ..., datetime.datetime(2020, 5, 28, 8, 41, 58)], length=130\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eopatch = download_task.execute(bbox=roi_bbox, time_interval=time_interval)\n",
    "\n",
    "eopatch_clean = filter_clouds.execute(eopatch)\n",
    "\n",
    "eopatch_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help function to create GIFs\n",
    "The function uses a `rescale_factor` for a nicer picture. We set it to 2.8 by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(bands: np.ndarray, project_dir: str, filename: str, fps: int, rescale_factor: float = 2.8):\n",
    "    # Generates a GIF animation from an EOPatch.\n",
    "    with imageio.get_writer(os.path.join(project_dir, filename), mode=\"I\", fps=fps) as writer:\n",
    "        for image in bands:\n",
    "            writer.append_data(np.array(np.clip(rescale_factor * image[..., [2, 1, 0]], 0, 255), dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write clean EOPatch to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(bands=eopatch_clean[feat_bands] * 255, project_dir=\".\", filename=\"eopatch_clean.gif\", fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run registrations\n",
    "\n",
    "The constructor of the Registration objects takes the attribute type, field name and index of the channel to be used for registration, a dictionary specifying the parameters of the registration, and the interpolation method to be applied to the images. The interpolation methods are (NEAREST, LINEAR and CUBIC). Default is CUBIC. A nearest neighbour interpolation is used on ground-truth data to avoid creation of new labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thunder registration\n",
    "\n",
    "This algorithm computes translations only between pairs of images, using correlation on the Fourier transforms of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coregister_thunder = ThunderRegistrationTask(feat_bands, channel=2)\n",
    "\n",
    "eopatch_thunder = coregister_thunder(eopatch_clean)\n",
    "\n",
    "make_gif(bands=eopatch_thunder[feat_bands] * 255, project_dir=\".\", filename=\"eopatch_thunder.gif\", fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Cross-Correlation in OpenCV\n",
    "\n",
    "This algorithm uses intensity values to maximise cross-correlation between pair of images. It uses an Euler transformation (x,y translation plus rotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"MaxIters\": 200}\n",
    "\n",
    "coregister_ecc = ECCRegistrationTask(feat_bands, channel=2, params=params)\n",
    "\n",
    "eopatch_ecc = coregister_ecc(eopatch_clean)\n",
    "\n",
    "make_gif(bands=eopatch_ecc[feat_bands] * 255, project_dir=\".\", filename=\"eopatch_ecc.gif\", fps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-Based Registration in OpenCV\n",
    "\n",
    "Three transformation models are supported for point-based registration, i.e. Euler, PartialAffine and Homography. These methods compute feature descriptors (i.e. SIFT or SURF) of the pair of images to be registered, and estimate a robust transformation using RANSAC to align the matching points. These methods perform poorly compared to the other methods due to the inaccuracies of the feature extraction, point-matching and model fitting. If unplausible transformations are estimated, a warning is issued and an identity matrix is employed instead of the estimated transform. Default parameters are (Model=Euler, Descriptor=SIFT, RANSACThreshold=7.0, MaxIters=1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"Model\": \"Euler\", \"Descriptor\": \"SURF\", \"RANSACThreshold\": 7.0, \"MaxIters\": 1000}\n",
    "\n",
    "coregister_pbased = PointBasedRegistrationTask(feat_bands, channel=2, params=params)\n",
    "\n",
    "eopatch_pbased = coregister_pbased(eopatch_clean)\n",
    "\n",
    "make_gif(bands=eopatch_pbased[feat_bands] * 255, project_dir=\".\", filename=\"eopatch_pbased.gif\", fps=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
