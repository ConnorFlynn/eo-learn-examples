{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To: Crop type classification for Austria\n",
    "\n",
    "This example notebook shows the steps towards constructing an automated machine learning pipeline for crop type identification in an area of interest in Austria. Along the pipeline, two different approaches are applied and compared. The first one, the LightGBM, represents a state-of-the-art machine learning algorithm. The second one is a Temporal Convolutional Neural Network architecture from the field of deep learning. The prediction is performed on a time-series of Sentinel-2 scenes from 2018. The example notebook will lead you through the whole process of creating the pipeline, with details provided at each step (see **Overview**). \n",
    "\n",
    "## Before start\n",
    "Enjoying the functionality of eo-learn and the simplicity of this example workflow is preceded by the unavoidable setup of an adequate working environment. But trust us, it's worth it! And we'll take you by the hand.\n",
    "### Requirements\n",
    "#### Sentinel Hub account\n",
    "To run the example you'll need a Sentinel Hub account. If you do not have one yet, you can create a free trial account at the [Sentinel Hub webpage](https://services.sentinel-hub.com/oauth/subscription). If you are a researcher you can even apply for a free non-commercial account at the [ESA OSEO page](https://earth.esa.int/aos/OSEO).\n",
    "\n",
    "Once you have the account set up, login to [Sentinel Hub Configurator](https://apps.sentinel-hub.com/configurator/). By default you will already have the default configuration with an **instance ID** (alpha numeric code of length 36). For this tutorial we recommend that you create a new configuration (`Add new configuration`) and set the configuration to be based on **Python scripts template**. Such configuration will already contain all layers used in a more general Land Use/ Land Cover (LULC) example which are adopted for this example. Otherwise you will have to define the layers for your configuration yourself.\n",
    "\n",
    "One layer you have to define yourself is your \"MY-S2-L2A-BANDS\" layer. Therefore you: \n",
    "- log in to your Sentinel Hub account\n",
    "- go to `Configuration Utility` and access your newly created `LULC` configuration\n",
    "- here you choose `+ Add new layer` \n",
    "- your Layer name is `MY-S2-L2A-BANDS`\n",
    "- in red letters you are requested to _! Please select predefined product or enter your processing script_ - so you better do...\n",
    "- to set your custom script you copy/paste `return [B02,B03,B04,B05,B06,B07,B08,B8A,B11,B12]` into the `Custom script editor` and click `</> Set Custom Script`\n",
    "- You just told Sentinel Hub which bands you want to download in the following. Now, go on and `Save` your own layer\n",
    "\n",
    "After you have prepared the configuration please put configuration's **instance ID** into `sentinelhub` package's configuration file following the [configuration instructions](http://sentinelhub-py.readthedocs.io/en/latest/configure.html).\n",
    "\n",
    "#### Sentinel Hub Python package\n",
    "The [Sentinel Hub Python package](https://sentinelhub-py.readthedocs.io/en/latest/) allows users to make OGC (WMS and WCS) web requests to download and process satellite images within your Python scripts. It supports Sentinel-2 L1C and L2A, Sentinel-1, Landsat 8, MODIS and DEM data source.\n",
    "#### eo-learn library\n",
    "Between the acquisition of a satellite image and actionable information, there is a large processing effort. [eo-learn](https://eo-learn.readthedocs.io/en/latest/index.html) as a collection of modular Python sub-packages allows easy and quick pro-cessing of spatio-temporal data to prototype, build and automate these required large scale EO workflows for AOIs of any size. It also directly enables the application of state-of-the-art tools for computer vision, machine learning and deep learning packages in Python to the data. Especially for non-experts to the field of remote sensing and machine learning it makes extraction of valuable information from satellite imagery easier and more comfortable.\n",
    "\n",
    "## Overview\n",
    "With the help of the eo-learn library, the entire classification process can be executed in 4 processing blocks, i.e. `EOWorkflows`.\n",
    "1. Ground truth data\n",
    "2. EO data\n",
    "3. Feature engineering - Crop type grouping - Sampling\n",
    "4. Prediction\n",
    "\n",
    "**In more detail the notebook is structured as follows:**\n",
    "\n",
    "\n",
    "I. Imports\n",
    "\n",
    "II. Configurations\n",
    "### Part I\n",
    "1. BBox-Splitter\n",
    "    - Plot AOI and give the extent\n",
    "    - Create BBoxes\n",
    "    - Visualize the selection\n",
    "2. Add ground truth data\n",
    "    - Create EOPatches and add LPIS + area ratio\n",
    "3. Add EO data\n",
    "    - Choose EO features\n",
    "    - Clean EOPatch list\n",
    "4. Feature/ label engineering and Sampling\n",
    "    - Data visualization\n",
    "    - Resampling, Interpolation, LPIS data preparation\n",
    "    - Sampling\n",
    "    \n",
    "### Part II\n",
    "\n",
    "6. Prediction\n",
    "    - Set up and train LightGBM model\n",
    "    - Set up and train TempCNN model\n",
    "    - Model validation and evaluation\n",
    "    - Prediction\n",
    "    - Visualization of the results\n",
    "7. Next steps\n",
    "\n",
    "Now, after the setup you are curious what is next and can't wait to get your hands dirty? Well, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Lets start with some necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set module directory to system path\n",
    "import sys, os\n",
    "MAIN_FOLDER = os.getcwd()\n",
    "import_path = os.path.join(MAIN_FOLDER, 'Tasks')\n",
    "if import_path not in sys.path:\n",
    "    sys.path.append(import_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in modules\n",
    "import math\n",
    "import shutil\n",
    "import itertools\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "# Basics of Python data handling and visualization\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Imports from eo-learn, sentinelhub-py, and perceptive-sentinel\n",
    "from sentinelhub import CRS, BBoxSplitter, MimeType\n",
    "\n",
    "from eolearn.core import LinearWorkflow, FeatureType, SaveTask, OverwritePermission, LoadTask\n",
    "from eolearn.core import EOPatch, EOTask, CreateEOPatchTask, ZipFeatureTask, MapFeatureTask\n",
    "from eolearn.geometry import VectorToRaster, ErosionTask\n",
    "from eolearn.io import S2L2AWCSInput, AddSen2CorClassificationFeature, ExportToTiff\n",
    "from eolearn.mask import get_s2_pixel_cloud_detector, AddCloudMaskTask, AddValidDataMaskTask\n",
    "from eolearn.features import SimpleFilterTask, LinearInterpolation\n",
    "from eolearn.features import NormalizedDifferenceIndexTask, EuclideanNormTask\n",
    "\n",
    "# Machine learning\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Deep Learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Notebook specific classes and functions\n",
    "from CropTypeClassTasks import CleanLPIS, GroupLPIS, LPISCLASS, ConcatenateData, SamplingTaskTask\n",
    "from CropTypeClassTasks import train_test_split_eopatches, train_test_split_eopatch\n",
    "from CropTypeClassTasks import plot_confusion_matrix, PredictPatch, AddAreaRatio, FixLPIS, masking\n",
    "from CropTypeClassTasks import AddGeopediaVectorFeature, Sen2CorValidData, ValidDataFractionPredicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "In this part you can define your configurations. The basic configurations are set for an example running smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define in- and output folders\n",
    "output_path = os.path.join(MAIN_FOLDER, 'Output')\n",
    "general_data_path = os.path.join(MAIN_FOLDER, 'GeneralData')\n",
    "patch_path = os.path.join(MAIN_FOLDER, 'Output', 'EOPatches')\n",
    "thresLPIS_path = os.path.join(MAIN_FOLDER, 'Output', 'EOPatches_Low_LPIS_Thres')\n",
    "samples_path = os.path.join(MAIN_FOLDER, 'Output', 'Samples')\n",
    "models_path = os.path.join(MAIN_FOLDER, 'Output', 'Models')\n",
    "predictions_path = os.path.join(MAIN_FOLDER, 'Output', 'Predictions')\n",
    "\n",
    "# For reference colormap\n",
    "lpisclass_cmap = mpl.colors.ListedColormap([entry.color for entry in LPISCLASS])\n",
    "lpisclass_norm = mpl.colors.BoundaryNorm(np.arange(-0.5, 26, 1), lpisclass_cmap.N)\n",
    "class_names = [entry.class_name for entry in LPISCLASS]\n",
    "class_ids = [entry.id for entry in LPISCLASS]\n",
    "\n",
    "\n",
    "### 1. BBox-Splitter\n",
    "##  Plot AOI and give extent\n",
    "INPUT_FILE = os.path.join(general_data_path, 'Area_AOI.geojson') # Geojson or Shapefile of the area of interest\n",
    "austria = os.path.join(general_data_path, 'Area_Austria.geojson') # Geojson of austrian national borders\n",
    "crs = CRS.UTM_33N # wanted coordinate System of the AOI\n",
    "\n",
    "\n",
    "### 2. Add ground truth data\n",
    "## Create EOPatches and add LPIS + area ratio\n",
    "year = '2018' # year of interest\n",
    "layerID_dict = {'2018': 2647, '2017': 2034, '2016': 2033} # Layer IDs of Geopedia Layer\n",
    "layerID = layerID_dict[year] # Layer ID for Austria of year set by \"year\"\n",
    "patch_list = os.listdir(patch_path) # List of created EOPatches names\n",
    "\n",
    "\n",
    "### 3. Add EO data\n",
    "## Choose EO features\n",
    "maxcloud = 0.8 # maximum cloudcoverage of sentinel tiles used for download\n",
    "datafrac = 0.7 # keep only frames with valid data fraction over x%\n",
    "## Clean EOPatch list\n",
    "lpis_thres = 0.13 # Patches with less than x% of LPIS coverage are excluded in the following\n",
    "## Add EO data\n",
    "time_interval = [f'{year}-01-01', f'{year}-09-30'] # the start and end date for downloading satellite data\n",
    "\n",
    "\n",
    "### 4. Feature and label engineering\n",
    "## Feature concatenation, interpolation and LPIS data preparation\n",
    "day_range = 8 # the realtime range of valid satellite images is resampled to a x day equidistant range \n",
    "## Prepare LPIS data\n",
    "grouping_id = 'basic' # define grouping id (has to be identical to endings of the two grouping files)\n",
    "# File that contains LPIS Crop ID and wanted groups - Colums of shape: CROP_ID, english, slovenian, latin, GROUP_1\n",
    "lpis_to_group_file = os.path.join(general_data_path, 'at_lpis_{}_crop_to_group_mapping_{}.csv'.format(year, grouping_id))\n",
    "# File that contains the wanted groups and their ID - Colums of shape: GROUP_1, GROUP_1_ID\n",
    "crop_group_file = os.path.join(general_data_path, 'crop_group_1_definition_{}.csv'.format(grouping_id))\n",
    "\n",
    "\n",
    "### 5. Sampling\n",
    "## Sampling per EOPatch\n",
    "pixel_thres = 1000 # Pixel thresold necessary for a class to be considered in sampling\n",
    "samp_class = 500 # take x samples per class per EOPatch\n",
    "## Combine samples and split into train and test data\n",
    "test_ratio = 4 # take every xth patch for testing\n",
    "features_dict = 'FEATURES_SAMPLED' # name of the dictionary where the sample features are saved\n",
    "labels_dict = 'LPIS_class_{}_ERODED_SAMPLED'.format(grouping_id) # name of the dictionary where the sample labels are saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. From AOI to BBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot AOI and give extent\n",
    "Spotlight on your \"INPUT_FILE\" configuration! This is where you have the possibility to easily adapt the workflow to your needs. **Take your pick** and replace the AOI file in the _General data_ folder. Either shapefile or geojson formatted version of your AOI is split into smaller patches by `eo-learn`. The total number of patches depends on the AOIs size. Automated splitting is supposed to create patches of size 10 x 10 km. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Area of interest\n",
    "aoi = gpd.read_file(INPUT_FILE) # read AOI file\n",
    "\n",
    "aoi_shape = aoi.geometry.values[-1] # get aoi shape\n",
    "\n",
    "aoi = aoi.to_crs(crs={'init': CRS.ogc_string(crs)}) # assign coordinate system to \n",
    "\n",
    "# define BBox-Splitter split values\n",
    "ShapeVal_a = round(aoi_shape.bounds[2] - aoi_shape.bounds[0])\n",
    "ShapeVal_b = round(aoi_shape.bounds[3] - aoi_shape.bounds[1])\n",
    "\n",
    "SplitVal_a = max(1, int(ShapeVal_a/1e4))\n",
    "SplitVal_b = max(1, int(ShapeVal_b/1e4))\n",
    "\n",
    "# Give extent of AOI + grid count and plot AOI\n",
    "print('The extent of the AOI is {}m x {}m, so it is split into a grid of {} x {}.'.format(ShapeVal_a, \n",
    "                                                                                          ShapeVal_b, \n",
    "                                                                                          SplitVal_a, \n",
    "                                                                                          SplitVal_b))\n",
    "\n",
    "aoi.plot()\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BBoxes\n",
    "The simple patch polygons are transformed into bounding boxes suitable for serving as geometrical EOPatch frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split area of interest into an appropriate number of BBoxes\n",
    "bbox_splitter = BBoxSplitter([aoi_shape], crs, (SplitVal_a, SplitVal_b))\n",
    "\n",
    "bbox_list = np.array(bbox_splitter.get_bbox_list()) # get list of BBox geometries\n",
    "info_list = np.array(bbox_splitter.get_info_list()) # get list of x (column) and y(row) indices\n",
    "\n",
    "print('Each bounding box also has some info how it was created.\\nExample:\\n'\n",
    "      'bbox: {}\\ninfo: {}\\n'.format(bbox_list[0].__repr__(), info_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the selection\n",
    "First visualize the GeoDataFrame of the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GeoDataFrame of BBoxes\n",
    "geometry = [Polygon(bbox.get_polygon()) for bbox in bbox_list] # get geometry from bbox_list for creating GeoSeries\n",
    "idxs_x = [info['index_x'] for info in info_list] # get column index for naming EOPatch\n",
    "idxs_y = [info['index_y'] for info in info_list] # get row index for naming EOPatch\n",
    "\n",
    "gdf = gpd.GeoDataFrame({'index_x': idxs_x, 'index_y': idxs_y},\n",
    "                       crs={'init': CRS.ogc_string(crs)},\n",
    "                       geometry=geometry)\n",
    "\n",
    "shapefile_name = os.path.join(output_path, 'BBoxes.shp')\n",
    "gdf.to_file(shapefile_name)\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second visualize the split AOI with reference to Austrian national borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AOI overview\n",
    "austria_gdf = gpd.read_file(austria)\n",
    "\n",
    "fontdict = {'family': 'monospace', 'weight': 'normal', 'size': 11}\n",
    "\n",
    "# if bboxes have all same size, estimate offset\n",
    "xl, yl, xu, yu = gdf.geometry[0].bounds\n",
    "xoff, yoff = (xu - xl) / 3, (yu - yl) / 5\n",
    "\n",
    "# main figure\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "gdf.plot(ax=ax,facecolor='w',edgecolor='r',alpha=0.5,linewidth=5)\n",
    "aoi.plot(ax=ax, facecolor='w',edgecolor='k',alpha=0.5)\n",
    "austria_gdf.plot(ax=ax, facecolor='w',edgecolor='b',alpha=0.5)\n",
    "ax.set_title('Test Area Splitted');\n",
    "plt.axis('off')\n",
    "\n",
    "# sub figure\n",
    "a = plt.axes([0.2, 0.6, .2, .2])\n",
    "gdf.plot(ax=a, facecolor='w',edgecolor='r',alpha=0.5, linewidth=3)\n",
    "aoi.plot(ax=a, facecolor='w',edgecolor='k',alpha=0.5, linewidth=3)\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Add ground truth data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create EOPatches and add LPIS data + area ratio\n",
    "Now it's time to create `EOPatches` and start filling them with data.\n",
    "\n",
    "#### Add data\n",
    "* At first you transform your basic geometric frames into proper `EOPatches`. You can then fill these handy data containers endlessly. \n",
    "* As a start you add your ground truth data that is later used as a reference to validate your prediction results. Here, you use Austrian LPIS data containing agricultural information on the field-level. In the case of this example you download your 2018 data in vector format automatically from [Geopedia](http://portal.geopedia.world/) using Sentinel-Hub tasks. For further observation you can also download the complete and free dataset for Austria [here](https://www.data.gv.at/katalog/dataset?q=INVEKOS+Schl%C3%A4ge&sort=score+desc%2C+metadata_modified+desc). \n",
    "* Additionally a ratio value is added showing the percentage of the agricultural area in the respective `EOPatch`. The importance of this ratio will become apparent in the following steps.\n",
    "\n",
    "An `EOPatch` is created and manipulated using `EOTasks`. Due to the potentially large number of `EOPatches`, automation of the processing pipeline is absolutely crucial. Therefore `EOTasks` are chained in an `EOWorkflow`. In this example the final workflow is executed on all patches, which are saved to the specified directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your 1. EOWorkflow - Ground truth data\n",
    "The `EOTasks` need to be put in some order and executed one by one. This can be achieved by manually executing the tasks, or more conveniently, defining an `EOWorkflow` which does this for you.\n",
    "An `EOWorkflow` can be linear or more complex, but it should be acyclic. Here we will use the linear case of the EOWorkflow, available as `LinearWorkflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK FOR CREATING EOPATCH\n",
    "create = CreateEOPatchTask()\n",
    "\n",
    "# TASK FOR ADDING LPIS DATA FROM GEOPEDIA\n",
    "# here you can choose the year of interest\n",
    "# also you have to set the corresponding Geopedialayer-ID\n",
    "add_lpis = AddGeopediaVectorFeature((FeatureType.VECTOR_TIMELESS, 'LPIS_{}'.format(year)),\n",
    "                                        layer=layerID, year_filter=None, drop_duplicates=True)\n",
    "\n",
    "# TASK FOR ADDING AN AREA RATIO\n",
    "# the area ratio indicates the EOPatches proportion of LPIS coverage\n",
    "area_ratio = AddAreaRatio((FeatureType.VECTOR_TIMELESS, 'LPIS_{}'.format(year)),\n",
    "                              (FeatureType.SCALAR_TIMELESS, 'FIELD_AREA_RATIO'))\n",
    "\n",
    "# TASK FOR SAVING TO OUTPUT\n",
    "save = SaveTask(patch_path, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "\n",
    "# define the workflow\n",
    "workflow = LinearWorkflow(create, \n",
    "                          add_lpis, \n",
    "                          area_ratio, \n",
    "                          save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your first EOWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute workflow\n",
    "pbar = tqdm(total=len(bbox_list))\n",
    "for idx, bbox in enumerate(bbox_list):\n",
    "    bbox = bbox_splitter.bbox_list[idx]\n",
    "    info = bbox_splitter.info_list[idx]\n",
    "    patch_name = f'eopatch_{idx}_col-{info[\"index_x\"]}_row-{info[\"index_y\"]}'\n",
    "    workflow.execute({create:{'bbox':bbox}, save:{'eopatch_folder':patch_name}})\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the added vector data for one example EOPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name))\n",
    "\n",
    "# plot vector data\n",
    "print('Plotting LPIS vector data of eopatch: {}'.format(eopatch_name))\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "LPIS = eopatch.vector_timeless['LPIS_{}'.format(year)]\n",
    "LPIS.plot(column='SNAR_BEZEI', axes=ax, categorical=True)\n",
    "ax.set_aspect('auto')\n",
    "ax.set_xticks(ticks=[])\n",
    "ax.set_yticks(ticks=[])\n",
    "\n",
    "del eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the crop types in your AOI are very diverse. Each colour stands for one of the over 200 LPIS classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Add EO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose EO features\n",
    "Now, it's time to add Sentinel-2 data to the EOPatches. You are lucky to be using `eo-learn`, as this is simply done by setting up another single EOWorkflow including only a single EOTask for adding your satellite images. The remaining tasks allow you to create extensive valid data masks and useful indices using a ridiculously small amount of code.\n",
    "\n",
    "In detail you add:\n",
    "* L2A bands [B02,B03,B04,B05,B06,B07,B08,B8A,B11,B12]\n",
    "* Sen2cor's scene classification map and snow probability map\n",
    "* SentinelHub's cloud probability map and cloud mask\n",
    "* A mask of validity, based on acquired data from Sentinel and cloud coverage.\n",
    "\n",
    "    1. IS_DATA == True\n",
    "    2. CLOUD_MASK == 0 (1 indicates that pixel was identified to be covered with cloud)\n",
    "    \n",
    "\n",
    "* Filter out time frames with < 70 % valid coverage (no clouds)\n",
    "* Calculate and add NDVI, NDWI, NORM for helping the algorithm to detect relationships between the spectral bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up  your 2. EOWorkflow - EO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK TO LOAD EXISTING EOPATCH\n",
    "load = LoadTask(patch_path)\n",
    "\n",
    "# TASK TO ADD SENTINEL 2 LEVEL 2A DATA\n",
    "# Here also a simple filter of cloudy scenes is done. A detailed cloud cover \n",
    "# detection is performed within the next steps\n",
    "add_l2a = S2L2AWCSInput(layer='MY-S2-L2A-BANDS', \n",
    "                        resx='10m', \n",
    "                        resy='10m', \n",
    "                        maxcc=maxcloud, \n",
    "                        time_difference=timedelta(hours=2),\n",
    "                        raise_download_errors=False)\n",
    "\n",
    "# TASK TO ADD SEN2COR'S SCENE\n",
    "# add sen2cor's scene classification map and snow probability map\n",
    "add_scl = AddSen2CorClassificationFeature(sen2cor_classification='SCL', \n",
    "                                          layer='TRUE-COLOR-S2-L2A',\n",
    "                                          image_format=MimeType.TIFF_d32f, \n",
    "                                          raise_download_errors=False)\n",
    "\n",
    "# TASK FOR CLOUD INFO\n",
    "# cloud detection is performed at 160m resolution\n",
    "# and the resulting cloud probability map and mask\n",
    "# are scaled to EOPatch's resolution\n",
    "cloud_classifier = get_s2_pixel_cloud_detector(average_over=2, dilation_size=1, all_bands=False)\n",
    "add_clm = AddCloudMaskTask(cloud_classifier,\n",
    "                           'BANDS-S2CLOUDLESS',\n",
    "                           cm_size_y='160m',\n",
    "                           cm_size_x='160m',\n",
    "                           cmask_feature='CLM')\n",
    "\n",
    "# create valid data masks\n",
    "scl_valid_classes = [2, 4, 5, 6, 7]\n",
    "\n",
    "# TASKs FOR ADDING L2A and L1C VALID DATA MASKS\n",
    "# convert cloudmask to validmask\n",
    "add_clm_valid =MapFeatureTask((FeatureType.MASK, 'CLM'),\n",
    "                             (FeatureType.MASK, 'CLM_VALID'),\n",
    "                             np.logical_not)\n",
    "# combine IS_DATA and CLM_VALID\n",
    "add_l1c_valmask = ZipFeatureTask({FeatureType.MASK: ['IS_DATA', 'CLM_VALID']}, \n",
    "                            (FeatureType.MASK, 'L1C_VALID'),\n",
    "                            np.logical_and)\n",
    "# combine IS_DATA and SCL (using an erosion radius of 6 and a dilation radius of 22 pixel for SCL classes)\n",
    "add_l2a_valmask = AddValidDataMaskTask(Sen2CorValidData(scl_valid_classes, 6, 22), 'L2A_VALID')\n",
    "# combine all validmasks\n",
    "add_valmask = ZipFeatureTask({FeatureType.MASK: ['L1C_VALID', 'L2A_VALID']}, \n",
    "                            (FeatureType.MASK, 'VALID_DATA'),\n",
    "                            np.logical_and)\n",
    "\n",
    "# TASK TO FILTER OUT SCENES INCLUDING TOO MANY UNVALID PIXEL\n",
    "# keep frames with > x % valid coverage\n",
    "valid_data_predicate = ValidDataFractionPredicate(datafrac)\n",
    "filter_task = SimpleFilterTask((FeatureType.MASK, 'VALID_DATA'), valid_data_predicate)\n",
    "\n",
    "# TASK FOR CALCULATING INDICES\n",
    "# NDVI = Normalized Difference Vegetation Index\n",
    "# NDWI = Normalized Difference Water Index\n",
    "# NORM = Euclidean Norm\n",
    "ndvi = NormalizedDifferenceIndexTask((FeatureType.DATA, 'MY-S2-L2A-BANDS'), \n",
    "                                     (FeatureType.DATA, 'NDVI'),\n",
    "                                     [6, 2])\n",
    "ndwi = NormalizedDifferenceIndexTask((FeatureType.DATA, 'MY-S2-L2A-BANDS'), \n",
    "                                     (FeatureType.DATA, 'NDWI'),\n",
    "                                     [1, 6])\n",
    "norm = EuclideanNormTask((FeatureType.DATA, 'MY-S2-L2A-BANDS'), (FeatureType.DATA, 'NORM'))\n",
    "\n",
    "# TASK FOR SAVING TO OUTPUT\n",
    "save = SaveTask(patch_path, compress_level=1, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "\n",
    "workflow = LinearWorkflow(load, \n",
    "                          add_l2a, \n",
    "                          add_scl, \n",
    "                          add_clm, \n",
    "                          add_clm_valid, \n",
    "                          add_l1c_valmask, \n",
    "                          add_l2a_valmask, \n",
    "                          add_valmask, \n",
    "                          filter_task, \n",
    "                          ndvi, \n",
    "                          ndwi, \n",
    "                          norm, \n",
    "                          save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean EOPatch list\n",
    "Most likely, along with this innovative workflow, you are pushing humankind forward with other processes on your machine. Therefore you do not want to waste your ressources on EOPatches containing very little agricultural area. Before running your already set up EOWorkflow, clean your EOPatch list.\n",
    "\n",
    "Remember the earlier calculated LPIS ratio? From here on you only keep EOPatches containing more than 13% agricultural area. The irrelevant ones are moved to the sidetrack. If you want to use EOPatches more extensively covered with agricultural area simply increase your \"lpis_thres\" configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in GeoDataFrame label patches with certain thresold either as to do (1) or not to do (0)\n",
    "gdf[f'far{year}'] = -2.0\n",
    "for idx, row in gdf.iterrows():\n",
    "    patch_name = os.path.join(patch_path, f'eopatch_{idx}_col-{row.index_x}_row-{row.index_y}')\n",
    "    eop = EOPatch.load(str(patch_name), lazy_loading=True)\n",
    "    gdf.loc[idx, f'far{year}'] = eop.scalar_timeless['FIELD_AREA_RATIO'][0]\n",
    "    \n",
    "gdf[f'todo{year}'] = (gdf[f'far{year}'] > lpis_thres) * 1\n",
    "gdf.to_file(shapefile_name)\n",
    "\n",
    "# move EOPatch folders with LPIS coverage beneath thresold into seperate folder\n",
    "move = []\n",
    "patch_list_delete = gpd.read_file(shapefile_name)\n",
    "patch_list_delete = patch_list_delete[patch_list_delete[f'todo{year}'] == 0] # identify EOPatches with insufficient LPIS thresold\n",
    "\n",
    "# create list including names of the identified EOPatches\n",
    "for idx in patch_list_delete.index:\n",
    "    info = bbox_splitter.info_list[idx]\n",
    "    patch_name = f'eopatch_{idx}_col-{info[\"index_x\"]}_row-{info[\"index_y\"]}'\n",
    "    move.append(patch_name)\n",
    "    \n",
    "print('EOPatches moved to sidetrack: ' + str([patch_name for patch_name in move]))\n",
    "\n",
    "# move identified EOPatches to alternative folder\n",
    "for patch_name in move:\n",
    "    shutil.move(os.path.join(patch_path, patch_name), os.path.join(thresLPIS_path, patch_name))\n",
    "\n",
    "patch_list = os.listdir(patch_path) # update patch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run second EOWorkflow\n",
    "* Set up EOWorkflow? **Check!**\n",
    "* Ignored irrelevant EOPatches? **Check!**\n",
    "\n",
    "Then go ahead and run your EOWorkflow on the basis of your \"time_interval\" configuration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute workflow and save the names of those that failed\n",
    "failed = []\n",
    "\n",
    "pbar = tqdm(total=len(patch_list))\n",
    "for patch_name in patch_list:\n",
    "    # add EO data if possible\n",
    "    try:\n",
    "        workflow.execute({load: {'eopatch_folder': patch_name},\n",
    "                          add_l2a: {'time_interval': time_interval},\n",
    "                          save: {'eopatch_folder': patch_name}})\n",
    "    # append EOPatch name to list for further investigation\n",
    "    except Exception as ex:\n",
    "        print(f'Failed {patch_name} with {ex}')\n",
    "        failed.append(patch_name)\n",
    "\n",
    "    pbar.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature/ label engineering and Sampling\n",
    "The classifier you are using for the following prediction is very picky when it comes to the format of the input data. To feed your thoughtfully compiled data to the algorithm it needs some preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "\n",
    "Now, after all necessary data is added let's load a single EOPatch and look at the structure. By executing \n",
    "```\n",
    "EOPatch.load(os.path.join(patch_path, 'eopatch_0_col-0_row-0')\n",
    "```\n",
    "\n",
    "You obtain the following structure:\n",
    "\n",
    "```\n",
    "EOPatch(\n",
    "  data: {\n",
    "    MY-S2-L2A-BANDS: numpy.ndarray(shape=(39, 1028, 1033, 10), dtype=float32)\n",
    "    NDVI: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=float32)\n",
    "    NDWI: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=float32)\n",
    "    NORM: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=float32)\n",
    "  }\n",
    "  mask: {\n",
    "    CLM: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=bool)\n",
    "    CLM_VALID: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=bool)\n",
    "    IS_DATA: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=bool)\n",
    "    L1C_VALID: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=bool)\n",
    "    L2A_VALID: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=bool)\n",
    "    SCL: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=int32)\n",
    "    VALID_DATA: numpy.ndarray(shape=(39, 1028, 1033, 1), dtype=bool)\n",
    "  }\n",
    "  scalar: {}\n",
    "  label: {}\n",
    "  vector: {}\n",
    "  data_timeless: {}\n",
    "  mask_timeless: {}\n",
    "  scalar_timeless: {\n",
    "    FIELD_AREA_RATIO: numpy.ndarray(shape=(1,), dtype=float64)\n",
    "  }\n",
    "  label_timeless: {}\n",
    "  vector_timeless: {\n",
    "    LPIS_2018: geopandas.GeoDataFrame(columns=['geometry', 'FS_KENNUNG', 'SL_FLAECHE', 'ID', 'SNAR_BEZEI', 'DateImported'], length=4091, crs=EPSG:32633)\n",
    "  }\n",
    "  meta_info: {\n",
    "    maxcc: 0.8\n",
    "    service_type: 'wcs'\n",
    "    size_x: '10m'\n",
    "    size_y: '10m'\n",
    "    time_difference: datetime.timedelta(seconds=7200)\n",
    "    time_interval: ['2018-01-01', '2018-09-30']\n",
    "  }\n",
    "  bbox: BBox(((420862.3179607267, 5329537.336315366), (431194.28800678457, 5339817.792378783)), crs=CRS('32633'))\n",
    "  timestamp: [datetime.datetime(2018, 1, 6, 10, 4, 51), ..., datetime.datetime(2018, 9, 28, 10, 0, 24)], length=39\n",
    ")\n",
    "```\n",
    "\n",
    "As you can see your EO data and indices are stored in `data.FeatureType` your valid data masks in `mask.FeatureType` and your ground truth data in `vector_timeless.FeatureType`\n",
    "\n",
    "\n",
    "It is possible to access various EOPatch content via calls like:\n",
    "```\n",
    "eopatch.timestamp\n",
    "eopatch.vector_timeless['LPIS_2018']\n",
    "eopatch.data['NDVI'][0]\n",
    "eopatch.data['MY-S2-L2A-BANDS'][5][..., [3, 2, 1]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot RGB image\n",
    "In order to get a quick and realistic overview of your AOI you plot the true color image of one EOPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name), lazy_loading=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "plt.imshow(np.clip(eopatch.data['MY-S2-L2A-BANDS'][0][..., [2, 1, 0]] * 3.5, 0, 1))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "del eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot mean NDVI\n",
    "Plot the time-wise mean of NDVI for the whole region. Filter out clouds in the mean calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name), lazy_loading=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "ndvi = eopatch.data['NDVI']\n",
    "mask = eopatch.mask['VALID_DATA']\n",
    "ndvi[~mask] = np.nan\n",
    "ndvi_mean = np.nanmean(ndvi, axis=0).squeeze()\n",
    "im = ax.imshow(ndvi_mean, vmin=0, vmax=0.8, cmap=plt.get_cmap('YlGn'))\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "cb = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.01, aspect=100)\n",
    "cb.ax.tick_params(labelsize=20)\n",
    "plt.show()\n",
    "\n",
    "del eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all masks\n",
    "To see how the valid data masks look like and work together, you can compare them to a regular RGB image. For demonstration reasons a timeframe is selected which contains cloud-covered area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name), lazy_loading=True)\n",
    "\n",
    "tidx = 1\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.subplot(331)\n",
    "plt.imshow(np.clip(eopatch.data['MY-S2-L2A-BANDS'][tidx][..., [2,1,0]] * 3.5,0,1))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('MY-S2-L2A-BANDS - RGB')\n",
    "\n",
    "plt.subplot(332)\n",
    "plt.imshow(eopatch.mask['IS_DATA'][tidx].squeeze(), vmin=0, vmax=1, cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('IS_DATA - Data availability')\n",
    "\n",
    "plt.subplot(333)\n",
    "plt.imshow(eopatch.mask['CLM'][tidx].squeeze(), vmin=0, vmax=1, cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('CLM - Cloudmask')\n",
    "\n",
    "plt.subplot(334)\n",
    "plt.imshow(eopatch.mask['L1C_VALID'][tidx].squeeze(), vmin=0, vmax=1, cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('L1C_VALID - L1C valid data mask')\n",
    "\n",
    "plt.subplot(335)\n",
    "plt.imshow(eopatch.mask['L2A_VALID'][tidx].squeeze(), vmin=0, vmax=1, cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('L2A_VALID - L2A valid data mask')\n",
    "\n",
    "plt.subplot(336)\n",
    "plt.imshow(eopatch.mask['SCL'][tidx].squeeze(), cmap='jet')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('SCL - Sen2Cor scene classification map')\n",
    "\n",
    "plt.subplot(338)\n",
    "plt.imshow(eopatch.mask['VALID_DATA'][tidx].squeeze(), vmin=0, vmax=1, cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('VALID_DATA - Combined valid data mask')\n",
    "\n",
    "del eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see invalid pixel from the different cloud masks and Sen2Cor scene classification map are combined. For SCL the classes: \n",
    "* 1 SC_SATURATED_DEFECTIVE \n",
    "* 3 SC_CLOUD_SHADOW \n",
    "* 8 SC_CLOUD_MEDIUM_PROBABILITY \n",
    "* 9 CLOUD_HIGH_PROBABILITY \n",
    "* 10 THIN_CIRRUS \n",
    "* 11 SNOW \n",
    "\n",
    "are considered as invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spatial mean NDVI timeseries\n",
    "Plot the mean of NDVI over all pixels in a single patch throughout the year. Filter out clouds in the mean calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name), lazy_loading=True)\n",
    "\n",
    "ndvi_series = eopatch.data['NDVI']\n",
    "time = np.array(eopatch.timestamp)\n",
    "mask = eopatch.mask['VALID_DATA']\n",
    "t, w, h, _ = ndvi_series.shape\n",
    "\n",
    "ndvi_clean = ndvi_series.copy()\n",
    "ndvi_clean[~mask] = np.nan # set values of invalid pixels to NaN's\n",
    "\n",
    "# Calculate means, remove NaN's from means\n",
    "ndvi_mean = np.nanmean(ndvi_series.reshape(t, w * h).squeeze(), axis=1)\n",
    "ndvi_mean_clean = np.nanmean(ndvi_clean.reshape(t, w * h).squeeze(), axis=1)\n",
    "time_clean = time[~np.isnan(ndvi_mean_clean)]\n",
    "ndvi_mean_clean = ndvi_mean_clean[~np.isnan(ndvi_mean_clean)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "plt.plot(time_clean, ndvi_mean_clean, 's-', label = 'Mean NDVI with cloud cleaning')\n",
    "plt.plot(time, ndvi_mean, 'o-', label='Mean NDVI without cloud cleaning')\n",
    "plt.xlabel('Time', fontsize=15)\n",
    "plt.ylabel('Mean NDVI over patch', fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(loc=2, prop={'size': 15});\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "del eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series displayed looks very fragmented for the temporal resolution of the Sentinel 2 data to be so hyped, right?\n",
    "\n",
    "This is what you get if you choose to keep timeframes with valid data fraction over 70% only. You set the value in your \"datafrac\" configuration. If you expect a nice overview of vegetation growing stages, reality kicks in and gives you mostly cloudy conditions in the first months of the year.\n",
    "The good thing about being picky about the validity of your timeframes is reduced data volume. Invalid frames contain no additional value for your later analysis anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling - Interpolation - LPIS data preparation - Sampling\n",
    "### Feature concatenation and interpolation\n",
    "* For easier handling of the data you concatenate MY-S2-L2A-BANDS, NDVI, NDWI, NORM info into a single feature called FEATURES\n",
    "* Perform temporal interpolation (filling gaps and resampling to the same dates) by:\n",
    "    * creating a linear interpolation task in the temporal dimension\n",
    "    * providing the cloud mask to tell the interpolating function which values to update\n",
    "    * using only timeframes from a timerange all EOPatches have in common (from earliest date to latest date)\n",
    "\n",
    "### LPIS data preparation\n",
    "* From scratch, LPIS data is divided into 200 different crop type classes. As the classification is based on spectral signatures, those have to be distinctive. 200 classes are obviously too detailed for achieving accurate prediction results. Therefore you group these classes into reasonable groups also based on similar spectral characteristics using the two CSV files from the \"General data\" folder. The basic grouping defines 14 groups namely: Grass, Maize, Orchards, Peas, Potatoes, Pumpkins, Soybean, Summer cereals, Sunflower, Vegetables, Vine-yards, Winter cereals, Winter rape, Other. This grouping turned out to perform best in classification.\n",
    "* After the grouping, the data set stored in vector format is converted into a raster format. Thus, each EO pixel can be assigned to a crop type value. All polygons belonging to one of the classes are separately burned to the raster mask.\n",
    "* In order to get rid of artifacts with a width of 1 pixel, and mixed pixels at the edges between polygons of different classes you perform an erosion. That means a buffer of 1 pixel (10m) size is applied to each individual field in the border area.\n",
    "\n",
    "### Sampling\n",
    "By a spatial sampling of the EOPatches you randomly take a subset of pixels from a patch to use in the machine learning training and testing. Here you only want to consider classes that are represented to a certain quantity of pixels.\n",
    "* Remember your \"pixel_tres\" configuration - a threshold of 1000 pixel is necessary for a class to be considered in sampling\n",
    "* Remember your \"samp_class\" configuration - 500 pixel per class per EOPatch are sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linear interpolation find earliest and latest overlapping dates\n",
    "\n",
    "# list EOPatches\n",
    "eopatches = []\n",
    "\n",
    "patch_list = os.listdir(patch_path)\n",
    "\n",
    "for i in patch_list:\n",
    "    eopatches.append(EOPatch.load(os.path.join(patch_path, i), lazy_loading=True))\n",
    "\n",
    "eopatches = np.array(eopatches)\n",
    "\n",
    "# identify  earliest date\n",
    "timelist = []\n",
    "for eopatch in eopatches:\n",
    "    timelist.append(eopatch.timestamp[0])\n",
    "mindate = str(max(timelist).date())\n",
    "print('Earliest date: ' + str(max(timelist)))\n",
    "\n",
    "# identify  latest date\n",
    "timelist = []\n",
    "for eopatch in eopatches:\n",
    "    timelist.append(eopatch.timestamp[-1])\n",
    "maxdate = str(min(timelist).date())\n",
    "print('Latest date: ' + str(min(timelist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your 3. EOWorkflow - Feature engineering/ Crop type grouping/ Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK FOR LOADING EXISTING EOPATCHES\n",
    "load = LoadTask(patch_path)\n",
    "\n",
    "# TASK FOR CONCATENATION\n",
    "# bands and indices are concatenated into one features dictionary\n",
    "concatenate = ConcatenateData('FEATURES', ['MY-S2-L2A-BANDS','NDVI','NDWI','NORM'])\n",
    "\n",
    "# TASK FOR LINEAR INTERPOLATION\n",
    "# linear interpolation of full time-series and date resampling\n",
    "resample_range = (mindate, maxdate, day_range)\n",
    "linear_interp = LinearInterpolation(\n",
    "    'FEATURES', # name of field to interpolate\n",
    "    mask_feature=(FeatureType.MASK, 'VALID_DATA'), # mask to be used in interpolation\n",
    "    copy_features=[(FeatureType.VECTOR_TIMELESS, 'LPIS_{}'.format(year))], # features to keep\n",
    "    resample_range=resample_range, # set the resampling range\n",
    "    bounds_error=False # extrapolate with NaN's\n",
    ")\n",
    "\n",
    "# TASK TO FIX AUSTRIAN LPIS DATA\n",
    "# on the basis of the wrongly defined column \"SNAR_BEZEI\" \n",
    "# a column \"SNAR_BEZEI_NAME\" is added which defines the LPIS class\n",
    "fixlpis = FixLPIS(feature='LPIS_{}'.format(year), country='Austria')\n",
    "\n",
    "# TASK FOR GROUPING LPIS INTO WANTED CLASSES\n",
    "# on the basis of the two grouping files an individual crop type grouping can be applied\n",
    "# for changes these files have to be adapted\n",
    "grouplpis = GroupLPIS(year=year, lpis_to_group_file=lpis_to_group_file, crop_group_file=crop_group_file)\n",
    "\n",
    "# TASK FOR CONVERTING LPIS DATA FROM VECTOR TO RASTER FORMAT\n",
    "# multiple rasterized layers appling different crop type groupings can be stored in an EOPatch\n",
    "vtr = VectorToRaster(\n",
    "    vector_input=(FeatureType.VECTOR_TIMELESS, 'LPIS_{}'.format(year)), \n",
    "    raster_feature=(FeatureType.MASK_TIMELESS, 'LPIS_class_{}'.format(grouping_id)),\n",
    "    values_column='GROUP_1_ID',\n",
    "    raster_shape=(FeatureType.DATA, 'FEATURES'),\n",
    "    no_data_value=0)\n",
    "\n",
    "# TASK FOR EROSION\n",
    "# erode each class of the reference map\n",
    "erosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'LPIS_class_{}'.format(grouping_id),\n",
    "                                    'LPIS_class_{}_ERODED'.format(grouping_id)), disk_radius=1)\n",
    "\n",
    "# TASK FOR SPATIAL SAMPLING\n",
    "spatial_sampling = SamplingTaskTask(grouping_id, pixel_thres, samp_class)\n",
    "\n",
    "# TASK FOR SAVING TO OUTPUT\n",
    "save = SaveTask(patch_path, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "\n",
    "# define the workflow\n",
    "workflow = LinearWorkflow(load, \n",
    "                          concatenate, \n",
    "                          linear_interp, \n",
    "                          fixlpis, \n",
    "                          grouplpis, \n",
    "                          vtr, \n",
    "                          erosion, \n",
    "                          spatial_sampling,\n",
    "                          save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run third EOWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(patch_list))\n",
    "for patch_name in patch_list:\n",
    "    extra_param = {load: {'eopatch_folder': patch_name},\n",
    "                   grouplpis: {'col_cropN_lpis': 'SNAR_BEZEI_NAME',\n",
    "                              'col_cropN_lpistogroup': 'CROP_ID'},\n",
    "                   save: {'eopatch_folder': patch_name}}\n",
    "\n",
    "    workflow.execute(extra_param)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOPatch data visualization\n",
    "\n",
    "Now, after all the data is transformed and sampled let's load the single EOPatch again and look at the structure. By executing \n",
    "```\n",
    "EOPatch.load(os.path.join(patch_path, 'eopatch_0_col-0_row-0')\n",
    "```\n",
    "\n",
    "You obtain the following structure:\n",
    "\n",
    "\n",
    "```\n",
    "EOPatch(\n",
    "  data: {\n",
    "    FEATURES: numpy.ndarray(shape=(31, 1033, 1040, 13), dtype=float64)\n",
    "    FEATURES_SAMPLED: numpy.ndarray(shape=(31, 6000, 1, 13), dtype=float64)\n",
    "  }\n",
    "  mask: {}\n",
    "  scalar: {}\n",
    "  label: {}\n",
    "  vector: {}\n",
    "  data_timeless: {}\n",
    "  mask_timeless: {\n",
    "    LPIS_class_basic: numpy.ndarray(shape=(1033, 1040, 1), dtype=uint8)\n",
    "    LPIS_class_basic_ERODED: numpy.ndarray(shape=(1033, 1040, 1), dtype=uint8)\n",
    "    LPIS_class_basic_ERODED_SAMPLED: numpy.ndarray(shape=(6000, 1, 1), dtype=uint8)\n",
    "  }\n",
    "  scalar_timeless: {}\n",
    "  label_timeless: {}\n",
    "  vector_timeless: {\n",
    "    LPIS_2018: geopandas.GeoDataFrame(columns=['geometry', 'FS_KENNUNG', 'SL_FLAECHE', 'ID', 'SNAR_BEZEI', 'DateImported', 'SNAR_BEZEI_NAME', 'CROP_ID', 'english', 'slovenian', 'latin', 'GROUP_1', 'GROUP_1_original', 'GROUP_1_ID'], length=4140, crs=epsg:32633)\n",
    "  }\n",
    "  meta_info: {}\n",
    "  bbox: BBox(((420717.14926283853, 5329441.919254168), (431121.7036578405, 5339770.083848184)), crs=EPSG:32633)\n",
    "  timestamp: [datetime.datetime(2018, 1, 29, 0, 0), ..., datetime.datetime(2018, 9, 26, 0, 0)], length=31\n",
    ")\n",
    "```\n",
    "\n",
    "Things have changed, haven't they?\n",
    "\n",
    "Your 10 spectral bands and 3 indices are combined in `FEATURES` and the randomly sampled pixels are stored in `FEATURES_SAMPLED`. After filtering, your valid data masks have been deleted and your eroded and sampled reference data is available in practical raster format as `mask_timeless.FeatureType`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine samples and split into train and test data\n",
    "As you performed the spatial sampling for each patch separately you have to combine the samples. But first you have to assign your EOPatches either to the training or validation dataset. In this case you take one in four EOPatches for testing.\n",
    "\n",
    "Only classes present in both train and test dataset are considered in the classification.\n",
    "\n",
    "The sampled features and labels are loaded and reshaped into $n \\times m$, where $n$ represents the number of training pixels, and $m = f \\times t$ the number of all features, with $f$ the size of bands and band combinations (in this example 13) and $t$ the length of the resampled time-series (in this example 34)\n",
    "\n",
    "Terminology: In data science features are commonly refered to as \"X\" and labels as \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_list = os.listdir(patch_path) # update patch list\n",
    "\n",
    "# combine EOPatches to one dataset\n",
    "eopatches = []\n",
    "for i in patch_list:\n",
    "    eopatches.append(EOPatch.load(os.path.join(patch_path, i), lazy_loading=True))\n",
    "\n",
    "eopatches = np.array(eopatches)\n",
    "\n",
    "# depending on the number of EOPatches adjust test_ratio if necessary and split into test and train data accordingly\n",
    "if len(patch_list) == 1:\n",
    "    # split combined dataset into train and test data\n",
    "    X_train, X_test, y_train, y_test, n_timesteps, n_features = train_test_split_eopatch(eopatches, \n",
    "                                                                features_dict, \n",
    "                                                                labels_dict)\n",
    "\n",
    "elif len(patch_list) < 4:\n",
    "    test_ratio = 3\n",
    "    # split combined dataset into train and test data\n",
    "    X_train, X_test, y_train, y_test, n_timesteps, n_features = train_test_split_eopatches(eopatches, \n",
    "                                                                  test_ratio, \n",
    "                                                                  features_dict, \n",
    "                                                                  labels_dict)\n",
    "\n",
    "else:\n",
    "    # split combined dataset into train and test data\n",
    "    X_train, X_test, y_train, y_test, n_timesteps, n_features = train_test_split_eopatches(eopatches, \n",
    "                                                                  test_ratio, \n",
    "                                                                  features_dict, \n",
    "                                                                  labels_dict)\n",
    "\n",
    "# mask out labels that are not in both train and test data and also mask out samples where features include NaN values\n",
    "X_train, X_test, y_train, y_test = masking(X_train, X_test, y_train, y_test)\n",
    "\n",
    "total_samp_count = X_train.shape[0] + X_test.shape[0]\n",
    "print('From your {} EOPatch(es) at total of {} samples were taken. '\n",
    "      'This sampling dataset includes {} training and {} test samples.'.format(len(patch_list), \n",
    "                                                                               total_samp_count, \n",
    "                                                                               X_train.shape[0], \n",
    "                                                                               X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sample distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "y_ids_train, y_counts_train = np.unique(y_train, return_counts=True)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(range(len(y_ids_train)), y_counts_train)\n",
    "plt.xticks(range(len(y_ids_train)), [class_names[i] for i in y_ids_train], rotation=90, fontsize=20);\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid(True)\n",
    "plt.title('Training samples', size=20)\n",
    "\n",
    "y_ids_test, y_counts_test = np.unique(y_test, return_counts=True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(len(y_ids_test)), y_counts_test)\n",
    "plt.xticks(range(len(y_ids_test)), [class_names[i] for i in y_ids_test], rotation=90, fontsize=20);\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid(True)\n",
    "plt.title('Test samples', size=20)\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see you have managed to generate a well balanced dataset. In both your 3/4 training and 1/4 test dataset no group is under or over represented, which provides a reasonable basis for the following classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and one-hot-encoding\n",
    "In the following you want to feed your samples into two different algorithms. To guarantee equivalent conditions for both models you need scaled features and one-hot-endcoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train = np.reshape(X_train, (-1,n_timesteps,n_features))\n",
    "X_test = np.reshape(X_test, (-1,n_timesteps,n_features))\n",
    "# save feature related scaling properties\n",
    "joblib.dump(scaler, os.path.join(samples_path, \n",
    "                                 'Scaler_{}.bin'.format(grouping_id)), \n",
    "                                 compress=True)\n",
    "\n",
    "# labels one- hot-encoding\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit(np.array(class_ids).reshape(-1, 1))\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)\n",
    "label_count = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save or load samples (optional)\n",
    "You can choose to save your samples for later applications. For entering the upcoming part of prediction, this is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save samples(optional)\n",
    "np.save(os.path.join(samples_path, 'X_train_{}'.format(grouping_id)), X_train)\n",
    "\n",
    "np.save(os.path.join(samples_path, 'X_test_{}'.format(grouping_id)), X_test)\n",
    "\n",
    "np.save(os.path.join(samples_path, 'y_train_{}'.format(grouping_id)), y_train)\n",
    "\n",
    "np.save(os.path.join(samples_path, 'y_test_{}'.format(grouping_id)), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load samples(optional)\n",
    "X_train = np.load(os.path.join(samples_path, 'X_train_{}.npy'.format(grouping_id)))\n",
    "\n",
    "X_test = np.load(os.path.join(samples_path, 'X_test_{}.npy'.format(grouping_id)))\n",
    "\n",
    "y_train = np.load(os.path.join(samples_path, 'y_train_{}.npy'.format(grouping_id)))\n",
    "\n",
    "y_test = np.load(os.path.join(samples_path, 'y_test_{}.npy'.format(grouping_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Prediction\n",
    "Congrats, you've mastered the heavy preprocessing steps! Now, this is where the magic of Machine and Deep Learning happens. \n",
    "\n",
    "State-of-the-art [LightGBM](https://github.com/Microsoft/LightGBM) is used as a ML model. It is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithms, used for many ML tasks.\n",
    "\n",
    "As novel competitors, [TempCNN](https://www.mdpi.com/2072-4292/11/5/523/htm#sec4-remotesensing-11-00523) DL architectures are entering the game. \n",
    "So far Convolutional Neural Networks were mainly and successfully applied for image and language recognition tasks. Modifying the convolutional filters of the architectures the Temporal CNN is supposed to exploit the temporal information of satellite image time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and train LightGBM model\n",
    "The [default hyper-parameters](https://lightgbm.readthedocs.io/en/latest/Parameters.html) are used in this example. For more info on [parameter tuning](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html), check the documentation of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set up training classes\n",
    "rev_y_train = [np.argmax(y, axis=None, out=None) for y in y_train]\n",
    "rev_y_train_unique = np.unique(rev_y_train)\n",
    "\n",
    "# reshape features from count-timeframes-features to timeframes-count-features\n",
    "a, b, c = X_train.shape\n",
    "X_train_lgbm = X_train.reshape(a,b * c)\n",
    "\n",
    "\n",
    "# Set up the LightGBM model\n",
    "model_lgbm = lgb.LGBMClassifier(\n",
    "    objective='multiclass', \n",
    "    num_class=len(rev_y_train_unique), \n",
    "    metric='multi_logloss'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_lgbm.fit(X_train_lgbm, rev_y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_lgbm, os.path.join(models_path, 'model_lgbm_CropTypeClass_{}.pkl'.format(grouping_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and train TempCNN model\n",
    "In this example an approved architecture from the scientific paper linked above is adopted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set up the TempCNN architecture\n",
    "model_tcnn = Sequential()\n",
    "model_tcnn.add(Conv1D(filters=5, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model_tcnn.add(Dropout(0.5))\n",
    "model_tcnn.add(Conv1D(filters=5, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model_tcnn.add(Dropout(0.5))\n",
    "model_tcnn.add(Conv1D(filters=5, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model_tcnn.add(Dropout(0.5))\n",
    "model_tcnn.add(Flatten())\n",
    "model_tcnn.add(Dense(256, activation='relu'))\n",
    "model_tcnn.add(Dense(label_count, activation='softmax'))\n",
    "model_tcnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_tcnn.fit(X_train, \n",
    "          y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          epochs=10, \n",
    "          batch_size=32, \n",
    "          verbose=1,  \n",
    "          shuffle=True)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_tcnn, os.path.join(models_path, 'model_tcnn_CropTypeClass_{}.pkl'.format(grouping_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and evaluation\n",
    "Validation of the models is a crucial step in data science. All models are wrong, but some are less wrong than others, so model evaluation is important.\n",
    "\n",
    "In order to validate the models, we use the training set to predict the classes, and then compare the predicted set of labels to the \"ground truth\".\n",
    "\n",
    "The validation is performed by evaluating various metrics, such as accuracy, precision, recall, $F_1$ score, some of which are nicely described [in this blog post](https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the overall accuracy (OA) and the weighted $F_1$ score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape features from count-timeframes-features to timeframes-count-features\n",
    "# and set up training classes\n",
    "d, e, f = X_test.shape\n",
    "X_test_lgbm = X_test.reshape(d, e * f)\n",
    "rev_y_test = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
    "\n",
    "# Load the models\n",
    "model_lgbm = joblib.load(os.path.join(models_path, 'model_lgbm_CropTypeClass_{}.pkl'.format(grouping_id)))\n",
    "model_tcnn = joblib.load(os.path.join(models_path, 'model_tcnn_CropTypeClass_{}.pkl'.format(grouping_id)))\n",
    "\n",
    "# get overall accuracy and weighted F1-score for LightGBM\n",
    "py_test_lgbm = model_lgbm.predict(X_test_lgbm)\n",
    "print('Classification accuracy LightGBM {:.1f}%'.format(100 * metrics.accuracy_score(rev_y_test, py_test_lgbm)))\n",
    "print('Classification F1-score LightGBM {:.1f}%'.format(100 * metrics.f1_score(rev_y_test, py_test_lgbm, average='weighted')))\n",
    "\n",
    "py_test_tcnn = model_tcnn.predict_classes(X_test)\n",
    "print('Classification accuracy TempCNN {:.1f}%'.format(100 * metrics.accuracy_score(rev_y_test, py_test_tcnn)))\n",
    "print('Classification F1-score TempCNN {:.1f}%'.format(100 * metrics.f1_score(rev_y_test, py_test_tcnn, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$F_1$ score, precision, and recall for each class separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM: F1-score, precision, and recall for each class separately\n",
    "class_labels = np.unique(rev_y_test)\n",
    "class_names = [entry.class_name for entry in LPISCLASS]\n",
    "\n",
    "f1_scores = metrics.f1_score(rev_y_test, py_test_lgbm, labels=class_labels, average=None)\n",
    "recall = metrics.recall_score(rev_y_test, py_test_lgbm, labels=class_labels, average=None)\n",
    "precision = metrics.precision_score(rev_y_test, py_test_lgbm, labels=class_labels, average=None) \n",
    "\n",
    "print('LightGBM:')\n",
    "print('             Class              =  F1    | Recall   | Precision')\n",
    "print('         --------------------------------------------------')\n",
    "for idx, croptype in enumerate([class_names[idx] for idx in class_labels]):\n",
    "    print('         * {0:20s} = {1:2.1f}    |  {2:2.1f}     | {3:2.1f}'.format(croptype, \n",
    "                                                                         f1_scores[idx] * 100, \n",
    "                                                                         recall[idx] * 100, \n",
    "                                                                         precision[idx] * 100))\n",
    "\n",
    "# TempCNN: F1-score, precision, and recall for each class separately\n",
    "class_names = [entry.class_name for entry in LPISCLASS]\n",
    "\n",
    "f1_scores = metrics.f1_score(rev_y_test, py_test_tcnn, labels=class_labels, average=None)\n",
    "recall = metrics.recall_score(rev_y_test, py_test_tcnn, labels=class_labels, average=None)\n",
    "precision = metrics.precision_score(rev_y_test, py_test_tcnn, labels=class_labels, average=None) \n",
    "\n",
    "print('TempCNN:')\n",
    "print('             Class              =  F1    | Recall   | Precision')\n",
    "print('         --------------------------------------------------')\n",
    "for idx, croptype in enumerate([class_names[idx] for idx in class_labels]):\n",
    "    print('         * {0:20s} = {1:2.1f}    |  {2:2.1f}     | {3:2.1f}'.format(croptype, \n",
    "                                                                         f1_scores[idx] * 100, \n",
    "                                                                         recall[idx] * 100, \n",
    "                                                                         precision[idx] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the standard Confusion Matrix for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "conf_matrix_gbm = metrics.confusion_matrix(rev_y_test, py_test_lgbm)\n",
    "plot_confusion_matrix(conf_matrix_gbm,\n",
    "                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels],\n",
    "                      normalize=True,\n",
    "                      ylabel='Truth (CROPS)',\n",
    "                      xlabel='Predicted (LightGBM)',\n",
    "                      title='Confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the standard Confusion Matrix for TempCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "conf_matrix_gbm = metrics.confusion_matrix(rev_y_test, py_test_tcnn)\n",
    "plot_confusion_matrix(conf_matrix_gbm,\n",
    "                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels],\n",
    "                      normalize=True,\n",
    "                      ylabel='Truth (CROPS)',\n",
    "                      xlabel='Predicted (TempCNN)',\n",
    "                      title='Confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation of the models shows that for most of the groups both perform very well. However, there seem to be differences in their confusion for certain classes:\n",
    "* In this specific case orchards might catch your attention mostly. LightGBM performs worse than TempCNN. But more interesting than the overall accuracy is, that LightGBM classifies actual orchards as grass a lot (low recall) while, no other class is mistaken as orchards (high precision). In contrast TempCNN recognizes actual orchards well (high recall) but identifies acutal grass as orchards frequently (lower precision). Generally, confusion with grass class is not surprising, as there is a lot of it between the individual trees.\n",
    "* There is also poor performance received for potatoes in both models as their cultivation practices are quite similar to peas.\n",
    "* Poor performance for the group Other is expectable in consequence of its diverse class composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most important features\n",
    "\n",
    "The LightGBM model contains the information about feature importances. Let's check which features are most important for  classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name), lazy_loading=True)\n",
    "\n",
    "timeframe_count = eopatch.data['FEATURES'].shape[0]\n",
    "features_count = eopatch.data['FEATURES'].shape[3]\n",
    "\n",
    "del eopatch\n",
    "\n",
    "z = model_lgbm.feature_importances_.reshape((timeframe_count, features_count))\n",
    "\n",
    "fnames = ['B02','B03','B04','B05','B06','B07','B08','B8A','B11','B12','NDVI','NDWI','NORM']\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = plt.gca()\n",
    "\n",
    "# plot the importances\n",
    "im = ax.imshow(z, aspect=0.25)\n",
    "plt.xticks(range(len(fnames)), fnames, rotation=45, fontsize=20)\n",
    "plt.yticks(range(timeframe_count), ['T{}'.format(i) for i in range(timeframe_count)], fontsize=20)\n",
    "plt.xlabel('Bands and band related features', fontsize=20)\n",
    "plt.ylabel('Time frames', fontsize=15)\n",
    "plt.ylim(top=-0.5, bottom=timeframe_count - 0.5)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "cb = fig.colorbar(im, ax=[ax], orientation='horizontal', pad=0.01, aspect=100)\n",
    "cb.ax.tick_params(labelsize=20)\n",
    "cb.set_label('Feature importance', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the most important features for LightGBM are recorded within the main growth period. Here different growing stages can be detected that constitute certain crop types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Now that both models have been validated, the remaining thing is to predict the whole AOI. As LightGBM receives higher overall accurays it is used for further predictions. If you are interested in a specific crop group TempCNN is outperforming LightGBM simply change the following configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap commentation for using a different model\n",
    "\n",
    "# model = joblib.load(os.path.join(models_path, 'model_tcnn_CropTypeClass_{}.pkl'.format(grouping_id))) # load TempCNN model\n",
    "model = joblib.load(os.path.join(models_path, 'model_lgbm_CropTypeClass_{}.pkl'.format(grouping_id))) # load LightGBM model\n",
    "\n",
    "# load respective feature scaler\n",
    "scaler = joblib.load(os.path.join(samples_path, 'Scaler_{}.bin'.format(grouping_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following you define a workflow to make a prediction on the existing EOPatches. The EOTask accepts the features and the names for the labels. In addition you export GeoTIFF images of the prediction to easily access your visual results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your 4. EOWorklow - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK TO LOAD EXISTING EOPATCHES\n",
    "load = LoadTask(patch_path)\n",
    "\n",
    "# TASK FOR PREDICTION\n",
    "predict = PredictPatch(model, (FeatureType.DATA, 'FEATURES'), 'LBL_GBM', scaler)\n",
    "\n",
    "# TASK TO EXPORT TIFF\n",
    "export_tiff = ExportToTiff((FeatureType.MASK_TIMELESS, 'LBL_GBM'))\n",
    "tiff_location = predictions_path\n",
    "if not os.path.isdir(tiff_location):\n",
    "    os.makedirs(tiff_location)\n",
    "    \n",
    "# TASK FOR SAVING\n",
    "save = SaveTask(patch_path, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "\n",
    "\n",
    "workflow = LinearWorkflow(load,\n",
    "                          predict,\n",
    "                          export_tiff,\n",
    "                          save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run fourth EOWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_list = os.listdir(patch_path) # update patch list\n",
    "# execute workflow\n",
    "pbar = tqdm(total=len(patch_list))\n",
    "for patch_name in patch_list:\n",
    "    extra_param = {load: {'eopatch_folder': patch_name}, \n",
    "                   export_tiff: {'filename': '{}/prediction_{}.tiff'.format(predictions_path, patch_name)}, \n",
    "                   save: {'eopatch_folder': patch_name}}\n",
    "\n",
    "    workflow.execute(extra_param)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOPatch data visualization\n",
    "\n",
    "Finishing the last processing step, let's have a look at the final EOPatch by executing\n",
    "```\n",
    "EOPatch.load(os.path.join(patch_path, 'eopatch_0_col-0_row-0')\n",
    "```\n",
    "\n",
    "You obtain the following structure which is extended by your predicted data stored as `LBL_GBM` in `mask_timeless.FeatureType`:\n",
    "\n",
    "\n",
    "```\n",
    "EOPatch(\n",
    "  data: {\n",
    "    FEATURES: numpy.ndarray(shape=(34, 1028, 1033, 13), dtype=float64)\n",
    "    FEATURES_SAMPLED: numpy.ndarray(shape=(34, 6000, 1, 13), dtype=float64)\n",
    "  }\n",
    "  mask: {}\n",
    "  scalar: {}\n",
    "  label: {}\n",
    "  vector: {}\n",
    "  data_timeless: {}\n",
    "  mask_timeless: {\n",
    "    LBL_GBM: numpy.ndarray(shape=(1028, 1033, 1), dtype=int64)\n",
    "    LPIS_class_basic: numpy.ndarray(shape=(1028, 1033, 1), dtype=uint8)\n",
    "    LPIS_class_basic_ERODED: numpy.ndarray(shape=(1028, 1033, 1), dtype=uint8)\n",
    "    LPIS_class_basic_ERODED_SAMPLED: numpy.ndarray(shape=(6000, 1, 1), dtype=uint8)\n",
    "  }\n",
    "  scalar_timeless: {}\n",
    "  label_timeless: {}\n",
    "  vector_timeless: {\n",
    "    LPIS_2018: geopandas.GeoDataFrame(columns=['geometry', 'FS_KENNUNG', 'SL_FLAECHE', 'ID', 'SNAR_BEZEI', 'DateImported', 'SNAR_BEZEI_NAME', 'CROP_ID', 'english', 'slovenian', 'latin', 'GROUP_1', 'GROUP_1_original', 'GROUP_1_ID'], length=4091, crs=EPSG:32633)\n",
    "  }\n",
    "  meta_info: {}\n",
    "  bbox: BBox(((420862.3179607267, 5329537.336315366), (431194.28800678457, 5339817.792378783)), crs=CRS('32633'))\n",
    "  timestamp: [datetime.datetime(2018, 1, 6, 0, 0), ..., datetime.datetime(2018, 9, 27, 0, 0)], length=34\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predicted EOPatch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name), lazy_loading=True)\n",
    "\n",
    "# update colormap\n",
    "cb_classes = np.unique(np.unique(eopatch.mask_timeless['LBL_GBM']))\n",
    "custom_cmap = mpl.colors.ListedColormap([lpisclass_cmap.colors[i] for i in cb_classes])\n",
    "custom_norm = mpl.colors.BoundaryNorm(np.arange(-0.5, len(cb_classes), 1), custom_cmap.N)\n",
    "\n",
    "# mask prediction - exclude pixel with no LPIS reference\n",
    "labels = np.array(eopatch.mask_timeless['LPIS_class_{}'.format(grouping_id)])\n",
    "mask = labels == 0\n",
    "labelspred = np.array(eopatch.mask_timeless['LBL_GBM'])\n",
    "LBL = np.ma.masked_array(labelspred, mask)\n",
    "\n",
    "# plot figure\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "im = ax.imshow(LBL.squeeze(), cmap=lpisclass_cmap, norm=lpisclass_norm)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# plot colorbar\n",
    "cb = fig.colorbar(mpl.cm.ScalarMappable(norm=custom_norm, cmap=custom_cmap), \n",
    "                  orientation=\"horizontal\", \n",
    "                  pad=0.01, \n",
    "                  aspect=100)\n",
    "cb.ax.tick_params(labelsize=20)\n",
    "cb.set_ticks(range(len(cb_classes)))\n",
    "cb.ax.set_xticklabels([class_names[i] for i in cb_classes], rotation=90, fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "del eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ground truth and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name), lazy_loading=True)\n",
    "\n",
    "# mask prediction - exclude pixel with no LPIS reference\n",
    "labels = np.array(eopatch.mask_timeless['LPIS_class_{}'.format(grouping_id)])\n",
    "mask = labels == 0\n",
    "labelspred = np.array(eopatch.mask_timeless['LBL_GBM'])\n",
    "LBL = np.ma.masked_array(labelspred, mask)\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(20, 10))\n",
    "\n",
    "# plot prediction\n",
    "ax1 = plt.subplot(121)\n",
    "im = ax1.imshow(LBL.squeeze(), cmap=lpisclass_cmap, norm=lpisclass_norm)\n",
    "plt.title('Prediction')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_aspect('auto')\n",
    "\n",
    "# plot ground truth\n",
    "ax2 = plt.subplot(122)\n",
    "im = ax2.imshow(labels.squeeze(), cmap=lpisclass_cmap, norm=lpisclass_norm)\n",
    "plt.title('Ground truth')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_aspect('auto')\n",
    "\n",
    "axlist=[ax1,ax2]\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# plot colorbar\n",
    "cb = fig.colorbar(mpl.cm.ScalarMappable(norm=custom_norm, cmap=custom_cmap), \n",
    "                  ax = axlist,\n",
    "                  orientation=\"horizontal\", \n",
    "                  pad=0.01, \n",
    "                  aspect=100)\n",
    "cb.ax.tick_params(labelsize=20)\n",
    "cb.set_ticks(range(len(cb_classes)))\n",
    "cb.ax.set_xticklabels([class_names[i] for i in cb_classes], rotation=90, fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "del eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close-up comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Draw the Reference map\n",
    "eopatch_name = 'eopatch_0_col-0_row-0' # get the name of the first newly created EOPatch\n",
    "eopatch = EOPatch.load(os.path.join(patch_path, eopatch_name), lazy_loading=True)\n",
    "\n",
    "# create red-green colormap\n",
    "colors = [(0, 1, 0), (1, 0, 0)]  # G -> R\n",
    "cmap_name = 'my_list'\n",
    "cm = LinearSegmentedColormap.from_list(\n",
    "        cmap_name, colors)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "inspect_size = 100\n",
    "\n",
    "w, h = labels.squeeze().shape\n",
    "\n",
    "w_min = np.random.choice(range(w - inspect_size))\n",
    "h_min = np.random.choice(range(h - inspect_size))\n",
    "\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "plt.imshow(labels.squeeze()[w_min: w_min + inspect_size, h_min : h_min + inspect_size],\n",
    "           cmap=lpisclass_cmap, norm=lpisclass_norm)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "ax.set_aspect('auto')\n",
    "plt.title('Ground truth', fontsize=20)\n",
    "\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "plt.imshow(LBL.squeeze()[w_min: w_min + inspect_size, h_min: h_min + inspect_size],\n",
    "           cmap=lpisclass_cmap, norm=lpisclass_norm)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "ax.set_aspect('auto')\n",
    "plt.title('Prediction', fontsize=20)\n",
    "\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "mask = LBL.squeeze() != labels.squeeze()\n",
    "plt.imshow(mask[w_min: w_min + inspect_size, h_min: h_min + inspect_size], cmap=cm)\n",
    "plt.xticks([])\n",
    "plt.yticks([]);\n",
    "ax.set_aspect('auto')\n",
    "plt.title('Difference', fontsize=20)\n",
    "\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "image = np.clip(eopatch.data['FEATURES'][8][..., [2, 1, 0]] * 3.5, 0, 1)\n",
    "plt.imshow(image[w_min: w_min + inspect_size, h_min: h_min + inspect_size])\n",
    "plt.xticks([])\n",
    "plt.yticks([]);\n",
    "ax.set_aspect('auto')\n",
    "plt.title('True Color', fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "del eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can probably see in the randomly chosen section of the AOI there are certain patterns of misclassified pixels:\n",
    "* There are complete fields mistaken as another crop group. In this case the algorithm got confused because of similar spectral characteristics. You already got an overview of the frequency and combination of those incidents in the evaluation part above.\n",
    "* Misclassified single pixels are usually located at the border of the respective fields. Here the \"mixed-pixel-problem\" impacts the prediction results. For the modeling these pixels were excluded, as they may include spectral reflectance values of different vegetation types and thereby confuse the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "Now, after your first successful classification you are hooked? But the region around Wels in Austria was surprisingly not your actual AOI or you want to try other vegetation groupings? Then here are some suggestions on how you could proceed:\n",
    "* **Customize configurations**\n",
    "\n",
    "    The notebook offers various possibilities to change parameters and evaluate their effects. Simply enter the configuration section in the beginning and modify e.g. cloudcover thresholds or your sampling strategy.\n",
    "\n",
    "\n",
    "* **Change the AOI within Austria**\n",
    "\n",
    "    This would be the simplest case to apply. You just have to place a Shapefile or Geojson of your own AOI in the location of the \"Area_AOI.geojson\" from the example. The size and shape of the included polygon are irrelevant. \n",
    "    \n",
    "    \n",
    "* **Try alternative crop groupings**\n",
    "\n",
    "    In order to regroup the LPIS classes you need to have a closer look at the two CSV files in the `GeneralData` folder. \n",
    "    * `at_lpis_2018_crop_to_group_mapping_basic.csv`: Here you can assign LPIS classes to different crop groups.\\\n",
    "       *_CROP_ID_* represents the respective LPIS class\\\n",
    "       *_GROUP_1_* represents the respective group you want a class in\n",
    "    * `crop_group_1_definition_basic.csv`: Here you can combine or separate individual crop groups by assigning the respective ID.\\\n",
    "      *_GROUP_1_* again represents the groups\\\n",
    "      *_GROUP_1_ID_* represents the respective numeric ID\n",
    "    \n",
    "    \n",
    "* **Apply the notebook to another country**\n",
    "\n",
    "    Another country means different AOI plus different LPIS classes. \n",
    "    * The first requires no additional effort. Change your AOI file and run the processes. EO data is downloaded and processed exactly as in the example. \n",
    "    * But when it comes to the ground truth data, this is were things get tricky as you additionally need to customize the CSV grouping files for your specific country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
